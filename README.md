# ğŸ›°ï¸ GeoExtract-VLM: Satellite Imagery Analysis Web Application

<div align="center">

![React](https://img.shields.io/badge/React-18+-61DAFB.svg?logo=react)
![Node.js](https://img.shields.io/badge/Node.js-18+-339933.svg?logo=node.js)
![Python](https://img.shields.io/badge/Python-3.10+-3776AB.svg?logo=python)
![MongoDB](https://img.shields.io/badge/MongoDB-6+-47A248.svg?logo=mongodb)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**A ChatGPT-like web application for satellite imagery analysis using Vision Language Models**

[Features](#features) â€¢ [Installation](#installation) â€¢ [Usage](#usage) â€¢ [Architecture](#architecture) â€¢ [Roadmap](#roadmap)

</div>

---

## ğŸ¯ Overview

GeoExtract-VLM is a full-stack web application that brings the power of Vision Language Models to satellite imagery analysis. Built with the MERN stack (MongoDB, Express, React, Node.js) and powered by a fine-tuned Qwen2-VL model, it provides a ChatGPT-like conversational interface for geospatial analysis.

### Key Capabilities

- ğŸ¢ **Building Detection & Counting** - Identify and count structures in satellite images
- ğŸ˜ï¸ **Urban Density Assessment** - Analyze population density and urban development patterns
- ğŸ›£ï¸ **Infrastructure Analysis** - Detect roads, transportation networks, and utilities
- ğŸŒ **Land Use Classification** - Categorize areas as residential, commercial, industrial, etc.
- ğŸ’¬ **Conversational AI Interface** - ChatGPT-like experience for image analysis

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **ChatGPT-like UI** | Modern, responsive chat interface |
| **Image Upload** | Drag & drop satellite imagery |
| **Chat History** | MongoDB-backed conversation storage |
| **Dark/Light Mode** | Toggle between themes |
| **Real-time Analysis** | Instant VLM-powered responses |
| **GGUF Model** | Optimized for CPU inference |

<div align="center">
<img src="docs/screenshot.png" alt="GeoExtract-VLM Screenshot" width="800"/>
</div>

---

## ğŸš€ Installation

### Prerequisites

- Node.js 18+
- Python 3.10+
- MongoDB (optional, for chat history)
- 4GB+ RAM recommended

### Quick Start

```bash
# Clone the repository
git clone https://github.com/CS-Fasih/GeoExract-Vlm-CLI-Based.git
cd GeoExract-Vlm-CLI-Based
```

#### 1ï¸âƒ£ Backend Setup

```bash
cd backend

# Install Node.js dependencies
npm install

# Install Python dependencies (for model service)
pip install -r requirements.txt

# Start the Express server
npm run dev

# In a new terminal, start the model service
python model_service.py
```

#### 2ï¸âƒ£ Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

#### 3ï¸âƒ£ Access the Application

Open your browser and navigate to: **http://localhost:5173**

---

## ğŸ’» Usage

### Web Interface

1. **Upload Image**: Click the ğŸ“· button to upload a satellite image
2. **Ask Questions**: Type your query in the chat input
3. **Get Analysis**: Receive detailed VLM-powered analysis
4. **View History**: Access previous conversations in the sidebar

### Example Queries

```
ğŸ¢ "How many buildings can you identify in this image?"
ğŸ˜ï¸ "Analyze the urban density and development pattern"
ğŸ›£ï¸ "Identify the road network and infrastructure"
ğŸŒ "What type of land use is predominant?"
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                         â”‚
â”‚                    http://localhost:5173                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend (Express.js)                          â”‚
â”‚                    http://localhost:5000                         â”‚
â”‚  â€¢ File uploads (Multer)                                         â”‚
â”‚  â€¢ Chat API endpoints                                            â”‚
â”‚  â€¢ MongoDB integration                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Model Service (FastAPI)                         â”‚
â”‚                    http://localhost:8000                         â”‚
â”‚  â€¢ GGUF model loading                                            â”‚
â”‚  â€¢ Image + text inference                                        â”‚
â”‚  â€¢ llama-cpp-python                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | React 18, Vite, Axios, Lucide Icons |
| **Backend** | Node.js, Express.js, Multer, Mongoose |
| **Model Service** | Python, FastAPI, llama-cpp-python |
| **Database** | MongoDB |
| **AI Model** | Qwen2-VL-2B (GGUF q4_k_m) |

---

## ğŸ“ Project Structure

```
GeoExtract-VLM/
â”œâ”€â”€ ğŸ“‚ frontend/                 # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main chat component
â”‚   â”‚   â””â”€â”€ App.css             # ChatGPT-like styles
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ğŸ“‚ backend/                  # Express + Python services
â”‚   â”œâ”€â”€ server.js               # Express API server
â”‚   â”œâ”€â”€ model_service.py        # FastAPI model service
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ package.json            # Node dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ training/                 # Model training scripts
â”‚   â”œâ”€â”€ step1_data_acquisition.py
â”‚   â”œâ”€â”€ step2_preprocessing.py
â”‚   â”œâ”€â”€ step3_finetuning.py
â”‚   â”œâ”€â”€ step4_inference.py
â”‚   â””â”€â”€ step5_export_gguf.py
â”‚
â”œâ”€â”€ ğŸ““ VLM_Satellite_Complete_Pipeline.ipynb
â”œâ”€â”€ ğŸ¤– qwen2vl-satellite-q4_k_m.gguf  # Fine-tuned model
â”œâ”€â”€ ğŸ“„ LICENSE
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ—ºï¸ Roadmap

### Phase 1: Core Web Application âœ…
- [x] Fine-tuned VLM model (Qwen2-VL-2B)
- [x] React frontend with ChatGPT-like UI
- [x] Express.js backend with file uploads
- [x] FastAPI model service
- [x] Dark/Light mode support
- [x] Basic chat functionality

### Phase 2: Enhanced Features (In Progress)
- [ ] User authentication (JWT)
- [ ] Chat history persistence
- [ ] Image gallery/history
- [ ] Export analysis reports
- [ ] Batch image processing

### Phase 3: Advanced Integration (Planned)
- [ ] Map integration (Leaflet/Mapbox)
- [ ] Drawing tools for ROI selection
- [ ] GeoJSON/KML export
- [ ] Multi-image comparison
- [ ] Time-series analysis

### Phase 4: Production Ready (Future)
- [ ] Docker containerization
- [ ] Kubernetes deployment
- [ ] Cloud hosting (AWS/GCP/Azure)
- [ ] API rate limiting
- [ ] Admin dashboard
- [ ] Mobile responsive optimization

---

## ğŸ”§ Configuration

### Environment Variables

**Backend (.env)**
```env
PORT=5000
MONGODB_URI=mongodb://localhost:27017/geoextract
MODEL_SERVICE_URL=http://localhost:8000
```

### Model Configuration

The GGUF model is loaded with these settings:
```python
Llama(
    model_path="qwen2vl-satellite-q4_k_m.gguf",
    n_ctx=2048,      # Context window
    n_threads=4,     # CPU threads
    n_gpu_layers=0   # CPU-only inference
)
```

---

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Frontend Load Time | < 1 second |
| API Response Time | < 100ms (without model) |
| Model Inference | 20-60 seconds (CPU) |
| Memory Usage | ~2GB |

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Muhammad Fasih**
- GitHub: [@CS-Fasih](https://github.com/CS-Fasih)

---

## ğŸ™ Acknowledgments

- [Qwen2-VL](https://github.com/QwenLM/Qwen2-VL) - Base model architecture
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - GGUF format and inference
- [OpenAI ChatGPT](https://chat.openai.com) - UI inspiration
- [Hugging Face](https://huggingface.co/) - Transformers library

---

<div align="center">

**â­ Star this repository if you find it useful!**

Made with â¤ï¸ for geospatial AI research

</div>
